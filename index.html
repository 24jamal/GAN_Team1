<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Welcome to GAN Mini Project Team : 1</title>
    
    <style>
        /* Add this style for the scrollable code block */
        #code-block {
            max-height: 300px; /* Set a maximum height for the code block */
            overflow-y: scroll; /* Enable vertical scrolling */
            border: 1px solid #ccc; /* Add a border for better visual separation */
            padding: 10px; /* Add padding for better readability */
            background-color: #F1EAFF;
        }
    </style>

<!-- Add this script at the end of your body tag -->
<script>
    document.addEventListener("DOMContentLoaded", function () {
        var scrollEndButton = document.getElementById("scroll-end");
    
        window.addEventListener("scroll", function () {
            // Show the scroll end button when the user scrolls beyond a certain point
            if (window.scrollY > 500) {
                scrollEndButton.classList.add("show");
            } else {
                scrollEndButton.classList.remove("show");
            }
        });
    
        // Scroll to the top when the button is clicked
        scrollEndButton.addEventListener("click", function () {
            window.scrollTo({ top: 0, behavior: "smooth" });
        });
    });
    </script>
    
    
</head>
<body>

    <header>
        <h1>GAN Mini project Team -1</h1>
    </header>
    <div class="container">
        <h1>Welcome to GAN Project</h1>
        <p>Professor-In-Charge: Prof. Deivamani</p>
        <p>Industry Expert: Mr. Muthumani</p>
    </div>

    <a href="GAN_Project_Report_Team1.pdf" download="GAN_Project_Report_Team1.pdf"><button>For Download Report PDF</button></a>


    <section id="abstract">
        <h3> <bold>Team Members :-</bold> Mohamed Jamaludeen 2022179006 : Neeraj Kumar Jha - 2022179057 : Jatin Durai - 2022179051 </h3>
        <h2>Abstract</h2>
        
        <p>
            Title: GANs for Automated House Plan Innovation: Blueprint Preprocessing, Autoencoding and Generation. <br>

This project leverages Generative Adversarial Networks (GANs) to revolutionize architectural design processes. It commences with meticulous blueprint preprocessing and employs autoencoding techniques to capture essential architectural features. The GAN then generates novel house plans, providing architects a powerful tool for efficient and creative design exploration. User collaboration is emphasized, integrating preferences and real-time feedback for adaptive design. Ethical considerations, including cultural sensitivity and environmental sustainability, are addressed to ensure responsible innovations. Scalability is a focal point, evaluating the framework's performance on diverse datasets and architectural styles. The project envisions a future where architects interact with dynamically generated 3D representations. Overall, it seeks to redefine architectural creativity, efficiency, and responsibility in the era of AI-assisted design.        
</p>
    </section>

    
    <section id="process-steps">
        
        <h2>Dataset Preprocessing</h2>
        
        <p>
<strong>1. Open Image in Photopea:</strong>
   - Go to the [Photopea website](https://www.photopea.com/).
   - Click on "File" in the top left corner and choose "Open" to load your blueprint image.
<br>
<strong>2. Check Current Resolution:</strong>
   - Go to "Image" > "Image Size" and check the current resolution of your image.
<br>
<strong>3. Set Resolution to 96 DPI:</strong>
   - If the resolution is different from 96 DPI, go to "Image" > "Image Size."
   - Uncheck the "Resample" option to maintain the original pixel dimensions.
   - Change the "Resolution" to 96 pixels/inch.
   <br>
   <strong>4.Crop and Resize:</strong> 
   - Use the Crop tool to remove any unnecessary parts of the image.
   - Resize the image to a consistent resolution suitable for your GAN input (e.g., 256x256 pixels).
   <br>
   <strong>5.Adjust Brightness and Contrast:</strong>
   
   - Go to "Image" > "Adjustments" > "Brightness/Contrast" to enhance or adjust the brightness and contrast as needed.
   <br>
   <strong>6.Remove Watermarks:</strong>
   - Use the Eraser tool or the Clone Stamp tool to remove any watermarks or unwanted elements from the image.
   <br>
   <strong>7.Convert to Grayscale:</strong>
   - If your GAN model works with grayscale images, convert the image to grayscale. Go to "Image" > "Mode" > "Grayscale."
   <br>
   <strong>8.Outline Only:</strong>
   - Create a new folder named "Outline."
   - Use tools such as the Pencil or Brush to outline the architectural features, such as walls, without internal details like doors.
   - Save the outlined image in JPG format to the "Outline" folder.
   <br>
   <strong>9.Outline with Internal Walls and Doors:</strong>
   - Create a new folder named "Outline_with_Internal_Walls_and_Doors."
   - Outline the architectural features, including internal walls and doors, using the Pencil or Brush tool.
   - Set the pixel size for doors to -1 and the pixel size for inner walls to -2. The pixel size for outer walls can remain consistent (e.g., 4 pixels).
   - Save the outlined image in JPG format to the "Outline_with_Internal_Walls_and_Doors" folder.
   <br>
   <strong>10. Repeat for Multiple Images:</strong>
    - If you have a dataset of blueprint images, repeat the above steps for each image in your dataset.
    <br>       
</p>
    </section>

    <section id="images-original">
        <h2>Unprocessed Images- Original</h2>
        <div class="image-container_orig">
            <img src="1455.jpg" alt="Image 1"> 
            <img src="1128.jpg" alt="Image 2">
            <img src="1444.jpg" alt="Image 3">
            <img src="1162.jpg" alt="Image 4">
            <img src="1414.jpg" alt="Image 5"> 
            <!-- Add more images as needed -->
        </div>
    </section>

    <section id="images-outline">
        <h2>Processed Images: Outline-InnerWalls</h2>
        <div class="image-container10">
            <img src="Processed_inlines/1455.jpg" alt="Image 1">
            <img src="Processed_inlines/1128.jpg" alt="Image 2">
            <img src="Processed_inlines/1444.jpg" alt="Image 3">
            <img src="Processed_inlines/1162.jpg" alt="Image 4">
            <img src="Processed_inlines/1414.jpg" alt="Image 5">
            <!-- Add more images as needed -->
        </div>
    </section>

    <section id="images-outlineline">
        <h2>Processed Images: Out</h2>
        <div class="image-container100">
            <img src="Processed_Ouline/1455.jpg" alt="Image 1">
            <img src="Processed_Ouline/1128.jpg" alt="Image 2">
            <img src="Processed_Ouline/1444.jpg" alt="Image 3">
            <img src="Processed_Ouline/1162.jpg" alt="Image 4">
            <img src="Processed_Ouline/1414.jpg" alt="Image 5">
            <!-- Add more images as needed -->
        </div>
    </section>

    

    <section id="video">
        <h2>Video about the project</h2>
        <video controls class="center-video">
            
            <source src="GAN_video.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        
    </section>
    

    <section id="code-block">
        <h3>Plant Image Preprocessing</h3>
        <pre>
            <code>
from torchvision.datasets import ImageFolder
from torchvision.transforms import Compose, Resize, ToTensor

transf = Compose([Resize((128, 128)), ToTensor()])
noise_train = ImageFolder("./PlantVillage/Noisy_Dataset/Train_Data/", transform=transf)
pure_train = ImageFolder("./PlantVillage/Pure_Dataset/Train_Data/", transform=transf)
noise_test = ImageFolder("./PlantVillage/Noisy_Dataset/Test_Data/", transform=transf)
pure_test = ImageFolder("./PlantVillage/Pure_Dataset/Test_Data/", transform=transf)

pure_data = glob("./PlantVillage/Pure_Dataset/Train_Data/P*/*")

# Use list comprehension to read and resize images
pure_images = [
resize(imread(file), (128, 128, 3), anti_aliasing=True) for file in pure_data
]

# Converting the images into float32 array
images_pure = np.asarray(pure_images, dtype="float32")
print("Dataset:", images_pure.shape)

import matplotlib.pyplot as plt

for i in range(9):
plt.subplot(3, 3, i + 1)
plt.axis("off")
plt.imshow(images_pure[i], cmap="gray")

test_data = glob("./PlantVillage/Noisy_Dataset/Test_Data/P*/*")

# Use list comprehension to read and resize images
images = [resize(imread(file), (128, 128, 3), anti_aliasing=True) for file in test_data]

# Converting the images into float32 array
images_test = np.asarray(images, dtype="float32")
print("Dataset:", images_test.shape)

for i in range(9):
plt.subplot(3, 3, i + 1)
plt.axis("off")
plt.imshow(images_test[i], cmap="gray")

test_data = glob("./PlantVillage/Pure_Dataset/Test_Data/P*/*")

# Use list comprehension to read and resize images
images = [resize(imread(file), (128, 128, 3), anti_aliasing=True) for file in test_data]

# Converting the images into float32 array
images_ground = np.asarray(images)
images_ground = images_ground.astype("float32")
print("Dataset:", images_ground.shape)

from torchvision.datasets import ImageFolder
from torchvision.transforms import Compose, Resize, ToTensor

transf = Compose([Resize((128, 128)), ToTensor()])
noise_train = ImageFolder("./PlantVillage/Noisy_Dataset/Train_Data/", transform=transf)
pure_train = ImageFolder("./PlantVillage/Pure_Dataset/Train_Data/", transform=transf)
noise_test = ImageFolder("./PlantVillage/Noisy_Dataset/Test_Data/", transform=transf)
pure_test = ImageFolder("./PlantVillage/Pure_Dataset/Test_Data/", transform=transf)

for i in range(9):
plt.subplot(3, 3, i + 1)
plt.axis("off")
plt.imshow(images_ground[i], cmap="gray")

import torch
from torch.utils.data import TensorDataset, DataLoader

train_loader = DataLoader(noise_train, batch_size=16)
pure_loader = DataLoader(pure_train, batch_size=16)
test_loader = DataLoader(noise_test, batch_size=16)
ground_loader = DataLoader(pure_test, batch_size=16)

model.eval()
total_loss = 0.0

# Iterate over batches in the train_loader and pure_loader
for batch_idx, (x, y) in enumerate(zip(train_loader, pure_loader)):
# Convert the images and labels to GPU for faster execution
t_x, _ = x
eval_x = t_x.to(device)
t_y, _ = y
eval_y = t_y.to(device)

# Passing the data to the model (Forward Pass)
decoded2 = model(eval_x)

# Calculating mean square error loss
loss = loss_func(decoded2, eval_y)
print(loss)

# Accumulate total loss
total_loss += loss.item()

# Save images (assuming save_pic is a function that saves the images)
for i in range(len(decoded2)):
save_pic(
decoded2[i].cpu().data, name=f"./PlantVillage/Denoised_Images/ae_{i}.jpg"
)

for i in range(64):
plt.subplot(8, 8, i + 1)
plt.axis("off")
plt.imshow(images_ground[i], cmap="gray")
            </code>
        </pre>
    </section>

    <section id="plant-images">
        <h2>Processed Images in Plant Dataset</h2>
        <div class="plant-container">
            <img src="plant1.png" alt="Image 1">
            <img src="plant2.png" alt="Image 2">
            <img src="plant3.png" alt="Image 3">
            <img src="plant4.png" alt="Image 4">
            <img src="plant5.png" alt="Image 5">
            <!-- Add more images as needed -->
        </div>
    </section>


    <section id="autoencoding">
        <h2>Autoencoding</h2>
        <p>
            Title: GANs for Automated House Plan Innovation: Blueprint Preprocessing, Autoencoding, and Generation

Abstract:

This project focuses on the application of Generative Adversarial Networks (GANs) in revolutionizing architectural design processes. The methodology involves the preprocessing of house blueprints to ensure data consistency, followed by autoencoding techniques to capture essential architectural features. The GAN is then employed to generate novel house plans by exploring the latent space, providing architects and designers with a tool for efficient and creative design exploration. The model's performance is evaluated using metrics such as structural coherence, stylistic fidelity, and diversity, aiming to enhance the generation of contextually relevant and aesthetically pleasing house plans.
        </p>
    </section>
    <h2>&nbsp;&nbsp;&nbsp;AutoEncode - Architecture</h2>
    <section id="AutoEncode_arch">

        <div class="image-container">
            <img src="AutoEncode.jpg" alt="Image 1">
            
            <!-- Add more images as needed -->
        </div>
    </section>

    






    <section id="GAN_Model">
        <h2>GAN Model</h2>
        <p>

            
To train a Generative Adversarial Network (GAN) for image generation of home blueprints, start by preparing a diverse dataset of blueprint images. Design the GAN architecture with a generator that creates synthetic blueprints from random noise and a discriminator that distinguishes real from generated images. Feed random noise into the generator and engage in an adversarial training process where the generator aims to produce convincing images, while the discriminator aims to correctly classify them. Adjust hyperparameters for optimal training, and evaluate the GAN's performance based on visual inspection and diversity of generated designs. Once trained, the generator can take random noise input to produce novel blueprint images, offering a powerful tool for creative exploration. Optionally, fine-tune the GAN for improved results and save the trained model for future use. This process enables architects and designers to generate realistic and varied home blueprints, revolutionizing the creative potential in architectural design.
        </p>
    </section>
    <h2>&nbsp;&nbsp;&nbsp;GAN Model - Architecture</h2>
    <section id="GAN_Model_arch">

        <div class="image-container">
            <img src="GAN_model_1.jpg" alt="Image 1">
            
            <!-- Add more images as needed -->
        </div>
    </section>








    <section id="Conclusion">
        <h2>Conclusion</h2>
        <p>
            The GAN Mini project Team -1 focuses on applying Generative Adversarial Networks (GANs) to revolutionize architectural design processes. The project includes preprocessing of house blueprints to ensure data consistency, followed by autoencoding techniques to capture essential architectural features. The GAN is then employed to generate novel house plans, providing architects and designers with an efficient and creative design exploration tool. The model's performance is evaluated using metrics such as structural coherence, stylistic fidelity, and diversity to enhance the generation of contextually relevant and aesthetically pleasing house plans.

            In conclusion, the project aims to harness the power of GANs for automated house plan innovation, emphasizing creativity, efficiency, and the generation of architecturally appealing designs. The methodology encompasses various stages, from preprocessing to GAN-based generation, and holds the potential to influence and enhance the field of architectural design.
            
        </p>
    </section>
    
    </section>
</body>

<!-- Add this HTML at the end of your body tag -->
<div id="scroll-end" title="Scroll to Top"><button>â†‘ Scroll to top</button></div>

</html>
